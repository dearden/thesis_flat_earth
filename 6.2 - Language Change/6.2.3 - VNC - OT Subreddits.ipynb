{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot VNC for r/conspiracy and r/science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utility_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ffb2de95fdff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"C:/Users/Eddie/Documents/language-change-application/flat-earth-forum/analysis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mhelpers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_posts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_toks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_top_n_toks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mvnc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVNC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_vnc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutility_functions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_data_windows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_time_windows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasic_preprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:/Users/Eddie/Documents/language-change-application/flat-earth-forum/analysis\\helpers.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msqlite3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"C:/Users/Eddie/Documents/language-change-methods\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mutility_functions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtokenise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_time_windows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_data_windows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utility_functions'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import itertools\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from nltk import ngrams as make_ngrams\n",
    "from scipy.cluster.hierarchy import cophenet\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "sys.path.insert(1, \"C:/Users/Eddie/Documents/language-change-methods\")\n",
    "sys.path.insert(1, \"C:/Users/Eddie/Documents/language-change-application/flat-earth-forum/analysis\")\n",
    "\n",
    "from helpers import load_posts, load_toks, load_pos, get_top_n_toks\n",
    "from vnc import VNC, plot_vnc\n",
    "from utility_functions import get_data_windows, get_time_windows, basic_preprocessing\n",
    "from features import get_tok_counts, function_words, combine_counts, make_feature_matrix\n",
    "from features import get_ngram_lr_and_ll\n",
    "from word_clouds import make_wordcloud\n",
    "\n",
    "# This method calculates cosine distance between two vectors.\n",
    "from scipy.spatial.distance import cosine as cosine_dist\n",
    "# This method simply inverts it to get similarity.\n",
    "cosine_sim = lambda x,y: 1 - cosine_dist(x,y)\n",
    "\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "convert_to_date = lambda x: datetime.strptime(x, \"%Y/%m/%d %H:%M:%S\")\n",
    "\n",
    "SUBREDDITS_FP = \"C:/Users/Eddie/Documents/Datasets/Reddit/Other\"\n",
    "TOKENS_FP = \"C:/Users/Eddie/Documents/Datasets/Reddit/Other/CHUNKS_COMMENTS_TOKENISED\"\n",
    "OUT_DIR = \"C:/Users/Eddie/Documents/Datasets/Flat Earth Graphs/VNC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 90000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_subreddit(db_fp):\n",
    "    conn = sqlite3.connect(db_fp)\n",
    "    comments = pd.read_sql_query(\"SELECT uid, time FROM comments\", conn)\n",
    "    comments.set_index(\"uid\", inplace=True)\n",
    "    comments['time'] = comments['time'].apply(convert_to_date)\n",
    "    comments.sort_values(\"time\", inplace=True)\n",
    "    conn.close()\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bow_counts(curr_toks):\n",
    "    bow_counts = {i: get_tok_counts(post) for i, post in curr_toks.items()}\n",
    "    bow_counts = {i: {tok: count for tok, count in post.items() if tok not in function_words} for i, post in bow_counts.items()}\n",
    "    top_n = get_top_n_toks(bow_counts.values(), 1000)\n",
    "    bow_counts = {i: {tok: count for tok, count in post.items() if tok in top_n} for i, post in bow_counts.items()}\n",
    "    bow_counts = pd.Series(bow_counts)\n",
    "    return bow_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_lists = lambda x: list(itertools.chain.from_iterable(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_align_toks(tok_fp, posts):\n",
    "    # Get the corresponding tokens\n",
    "    toks = {x[0]: x[1] for x in load_toks(tok_fp)}\n",
    "    toks = pd.Series(toks)\n",
    "    toks = toks[toks.index.isin(posts.index)]\n",
    "\n",
    "    # Remove the posts that don't have tokens\n",
    "    posts = posts[posts.index.isin(toks.index)]\n",
    "    # Align the ordering of forum posts and toks\n",
    "    toks = toks.loc[posts.index]\n",
    "\n",
    "    return toks, posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_subreddit_vnc(comments, toks, curr_name, window_size):\n",
    "    window_toks = {curr_date: merge_lists(toks.loc[curr_window.index]) \n",
    "                   for curr_date, curr_window in get_data_windows(comments, \n",
    "                                                                  window_size, \n",
    "                                                                  window_size)}\n",
    "    window_toks = pd.Series(window_toks)\n",
    "\n",
    "    # Get the counts\n",
    "    curr_counts = get_bow_counts(window_toks)\n",
    "\n",
    "    # Make the feature matrix\n",
    "    curr_feats, curr_feat_names = make_feature_matrix(curr_counts.to_dict(), False)\n",
    "    norm_feats = curr_feats / window_toks.apply(len).values[:,None]\n",
    "\n",
    "    feats = StandardScaler().fit_transform(norm_feats)\n",
    "    feats = pd.DataFrame(feats, index=curr_counts.index, columns=curr_feat_names)\n",
    "\n",
    "    print(\"-----------------------------------------------------------------\")\n",
    "    print(curr_name)\n",
    "    print(\"-----------------------------------------------------------------\")\n",
    "\n",
    "    vnc = VNC(feats, cosine_sim)\n",
    "    c, coph_dists = cophenet(vnc.d_list, pdist(feats, metric=\"cosine\"))\n",
    "    print(\"Cophenetic Correlation Coefficient: {}\".format(c))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    vnc.draw_dendrogram(ax=ax, colour=\"blue\")\n",
    "    ax.grid()\n",
    "    plt.show()\n",
    "    return vnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_kw(clusters, window_posts, toks, clust_windows):\n",
    "    num_clusts = len(set(clusters))\n",
    "    fig, axes = plt.subplots(1, num_clusts, figsize=(10*num_clusts, 8))\n",
    "    \n",
    "    kw_dic = dict()\n",
    "    for i, clust in enumerate(set(clusters)):\n",
    "        curr_clust_windows = clust_windows[clusters == clust]\n",
    "        clust_indices = merge_lists([window_posts[w] for w in curr_clust_windows])\n",
    "        clust_toks = toks.loc[clust_indices]\n",
    "        non_clust_toks = toks[~toks.index.isin(clust_indices)]\n",
    "        kw = get_ngram_lr_and_ll(clust_toks, non_clust_toks, 1, \"_\")\n",
    "        kw = kw.query(\"LR > 1 and freq1 > 100\").sort_values(\"LR\", ascending=False).head(100)[\"LR\"]\n",
    "        kw_dic[clust] = kw\n",
    "        \n",
    "        cloud = make_wordcloud(kw)\n",
    "        axes[i].imshow(cloud, aspect=\"auto\")\n",
    "        \n",
    "        axes[i].axes.xaxis.set_ticks([])\n",
    "        axes[i].axes.yaxis.set_ticks([])\n",
    "        axes[i].set_title(clust)\n",
    "        \n",
    "    plt.show()\n",
    "    return plot_cluster_kw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "vncs = dict()\n",
    "comment_dic = dict()\n",
    "tok_dic = dict()\n",
    "kw_dic = dict()\n",
    "clust_dic = dict()\n",
    "window_dic = dict()\n",
    "\n",
    "for curr_name in [\"conspiracy\", \"science\"]:         \n",
    "    curr_fp = os.path.join(SUBREDDITS_FP, \"{0}/{0}_sample.db\".format(curr_name))\n",
    "    tok_fp = os.path.join(TOKENS_FP, f\"{curr_name}_comments.json\")\n",
    "\n",
    "    startTime = datetime.now()\n",
    "    \n",
    "    # Get current comments and tokens\n",
    "    comments = read_subreddit(curr_fp)\n",
    "    toks, comments = get_align_toks(tok_fp, comments)\n",
    "    \n",
    "    # Make the VNC\n",
    "    curr_vnc = make_subreddit_vnc(comments, toks, curr_name, window_size)\n",
    "    \n",
    "    # Get keywords for each cluster\n",
    "    kw_dic[curr_name] = dict()\n",
    "    clusters = curr_vnc.get_clusters(1)\n",
    "    clust_dic[curr_name] = clusters\n",
    "    window_posts = {w: curr_posts.index for w, curr_posts in get_data_windows(comments, window_size, window_size)}\n",
    "    vnc_windows = curr_vnc.matrix.index\n",
    "    window_dic[curr_name] = vnc_windows\n",
    "    \n",
    "#     kw_dic[curr_name] = plot_cluster_kw(clusters, window_posts, toks, vnc_windows)\n",
    "    \n",
    "    \n",
    "#     # Store in dictionary\n",
    "#     vncs[curr_name] = curr_vnc\n",
    "#     comment_dic[curr_name] = comments\n",
    "#     tok_dic[curr_name] = toks\n",
    "    \n",
    "    print(\"Time taken: \", datetime.now() - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def ax_epochs_against_posts(times, counts, clust_starts, ax):\n",
    "    ax.plot(times, counts, c=\"#7fbf7b\")\n",
    "    for c_start in clust_starts:\n",
    "        ax.axvline(c_start, c=\"#af8dc3\", linestyle=\"--\")\n",
    "\n",
    "    for tick in ax.xaxis.get_ticklabels():\n",
    "        tick.set_size(14)\n",
    "\n",
    "    for tick in ax.yaxis.get_ticklabels():\n",
    "        tick.set_size(14)\n",
    "\n",
    "    ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fig = plt.figure(figsize=(14, 5))\n",
    "gs = fig.add_gridspec(len(clust_dic), hspace=0)\n",
    "axes = gs.subplots(sharex=True)\n",
    "\n",
    "\n",
    "for i, name in enumerate(clust_dic):\n",
    "    clusts = clust_dic[name]\n",
    "    dates = window_dic[name]\n",
    "    curr_fp = os.path.join(SUBREDDITS_FP, name, f\"{name}.db\")\n",
    "    comments = read_subreddit(curr_fp)\n",
    "    comments = comments.query(\"time >= @dates[0]\")\n",
    "    comments[\"flag\"] = [True] * len(comments)\n",
    "    \n",
    "    clust_starts = [dates[clusts==c][0] for c in set(clusts)]\n",
    "    rolling_counts = comments.rolling(\"90D\", on=\"time\").count()\n",
    "    ax_epochs_against_posts(rolling_counts[\"time\"], rolling_counts[\"flag\"], clust_starts, axes[i]) \n",
    "    axes[i].set_ylabel(name, size=14)\n",
    "    \n",
    "axes[-1].set_xlabel(\"Time\", size=14)\n",
    "fig.savefig(os.path.join(OUT_DIR, \"ot_reddit_comments_vnc_meta.pdf\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LanguageChangeApplication",
   "language": "python",
   "name": "languagechangeapplication"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
